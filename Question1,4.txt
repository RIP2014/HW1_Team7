1.1
Two planners were tested: Blackbox and FastForward. Blackbox will attempt to solve a problem 
by utilizing a variety of solvers, moving between its options when it detects one is not 
working effectively. Both use Graphplan as a primary solver, which constructs a noded graph of 
states linked by actions to locate a plan to reach the solution. FF doesn't utilize a variety 
of solvers, but makes up for this with its hill-climbing algorithm for estimating the number 
of steps needed to solve a problem.
1.2
FastForward was the faster of the two.
1.3
Blackbox wastes time attempting to solve problems using fewer moves than the minimum number 
required. The Tower's of Hanoi format makes it easy for FF to estimate the number of moves it 
will need to solve the problem.

4.1
The output is in file Question4-1Output.txt.
4.2
FF quickly determined the favorability of the largest disk being on the target peg and 
prioritized it in its search, and upon finding it disregarding actions that would disrupt this 
state. As the towers of hanoi allow you to ignore the largest disks once they are in the 
correct positions, this was an ideal optimization from it. It then looked for how to get the 
11th disk onto the 12th, and so on.The plan itself tells little, as the method by which it 
reaches this plan quickly determines the minimum number of moves needed to solve the problem, 
so the solution is optimal.
4.3
The problem with graphplan is that moves that return to previously considered states are still 
considered. Towers of Hanoi is reversible, so the sequence "Move the smallest disk from peg 1 
to peg 3, then move it from peg 3 back to peg 1" is still considered despite how pointless it 
is. The search through the graph may tend to ignore it with a decent heuristic, but when the 
path through a previous state is more complex, it becomes difficult to avoid wasting time.
To solve this, we can make use of the same technique used to optimize the sokoban planner, 
whereby we store some identifier for each state we've considered in memory. If the planner has 
already found a shorter way to reach a state, we can back up a step or explore the other 
approach to that state instead. This wouldn't be as effective on more complex problems, as 
when the states are more complex than this, more time is needed to compare the current one to 
the one in memory. It would also provide less benefit to problems with irreversible actions 
(e.g. a chess board where pawns can only move forward and pieces cannot be un-captured), as 
there is no chance of overlap with a prior state after one such action is taken. The planner 
would still be complete with this optimization.
